{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from gaze_graphs.iou_graph import IOUGraph\n",
    "from dgl_reflacx_tools.grid_tools import gridify, gridify_indices, gridify_by_indices, grid_readout\n",
    "\n",
    "from dgl_reflacx_tools.dgl_reflacx_collection import GraphCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pth = 'datasets/reflacx_densnet225_iou'\n",
    "collection = GraphCollection(dataset_pth, IOUGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting sample batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "grid_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [collection.fetch_by_dgl_index(i) for i in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [pair.dgl_graph for pair in pairs]\n",
    "labels = [pair.dgl_labels for pair in pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dgl.batch(graphs).to(device)\n",
    "labels = torch.cat(labels).reshape((batch_size, len(labels[0]))).to(device)\n",
    "\n",
    "batch, labels.shape, batch.device, labels.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting node features to be convolved. Concatenating (X, Y) position, duration, and extracted features from gaze crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_graph(g):\n",
    "    g.ndata['h'] = torch.cat([g.ndata['norm_x'].unsqueeze(1),\n",
    "                              g.ndata['norm_y'].unsqueeze(1),\n",
    "                              g.ndata['duration'].unsqueeze(1),\n",
    "                              g.ndata['feats']],\n",
    "                              dim=1)\n",
    "    g.update_all(fn.copy_e('weight', 'm'), fn.sum('m', 'neigh_weight'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin, fmax = torch.max(batch.ndata['feats'], dim=0).values, torch.min(batch.ndata['feats'], dim=0).values\n",
    "finterval = fmax - fmin\n",
    "fmin.shape, fmax.shape, finterval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((batch.ndata['feats'][123] - fmin) / finterval).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_graph(batch)\n",
    "batch.ndata['h'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convolution module on a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_messages(g, feat_nm, w_nm, sum_w_nm):\n",
    "    g.update_all(fn.v_mul_e(feat_nm, w_nm, 'm'), fn.sum('m', feat_nm))\n",
    "    g.ndata[feat_nm] = torch.divide(g.ndata[feat_nm], g.ndata[sum_w_nm].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 device,\n",
    "                 in_feats,\n",
    "                 out_feats,\n",
    "                 grid_size,\n",
    "                 pass_messages,\n",
    "                 activation=F.relu):\n",
    "        super(GridConv, self).__init__()\n",
    "        self.grid_lin = [[nn.Linear(in_feats, out_feats).to(device)\n",
    "                          for j in range(grid_size)]\n",
    "                         for i in range(grid_size)]\n",
    "        self.grid_size = grid_size\n",
    "        self.pass_messages = pass_messages\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, graph, feat_nm, grid_indices, out_feat_nm=None):\n",
    "        # pass messages (convolution) in whole graph\n",
    "        self.pass_messages(graph, feat_nm)\n",
    "        \n",
    "        # activation on grid cell model\n",
    "        grid = gridify_by_indices(graph, grid_indices)\n",
    "        new_feats = None\n",
    "        i_s = None\n",
    "        for i, line in enumerate(grid):\n",
    "            for j, sg in enumerate(line):\n",
    "                conv_feats = self.activation(self.grid_lin[i][j](sg.ndata[feat_nm]))\n",
    "                \n",
    "                #concatenate new features to uptadate parent graph\n",
    "                if new_feats is None:\n",
    "                    new_feats = conv_feats\n",
    "                    i_s = grid_indices[i][j]\n",
    "                else:\n",
    "                    new_feats = torch.cat([new_feats, conv_feats])\n",
    "                    i_s = torch.cat([i_s, grid_indices[i][j]])\n",
    "        \n",
    "        #update parent graph with features calculated by grid\n",
    "        i_s = torch.sort(i_s).indices\n",
    "        new_feats = new_feats[i_s]\n",
    "        graph.ndata[feat_nm if out_feat_nm is None else out_feat_nm] = new_feats\n",
    "        \n",
    "        return new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_message = lambda g, feat_nm: pass_messages(g, feat_nm, 'weight', 'neigh_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = GridConv(device, 1027, 1027, grid_size, f_message).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_i = gridify_indices(batch, grid_size)\n",
    "with batch.local_scope():\n",
    "   h = conv(batch, 'h', g_i)\n",
    "   h2 = conv(batch, 'h', g_i)\n",
    "\n",
    "with batch.local_scope():\n",
    "   h3 = conv(batch, 'h', g_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(h == h2), torch.all(h == h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining readout to be, for each grid cell, the concatenation of the sum of the cell's nodes duration with the convolved features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl_reflacx_tools.grid_tools import ReadoutPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflacxReadout(ReadoutPipeline):\n",
    "    def __init__(self):\n",
    "        feats_and_aggrs = [('duration', dgl.sum_nodes),\n",
    "                           ('h', dgl.mean_nodes)]\n",
    "        super().__init__(feats_and_aggrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflacxClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 device,\n",
    "                 input_dim,\n",
    "                 readout_dim,\n",
    "                 n_classes,\n",
    "                 grid_size,\n",
    "                 pass_messages,\n",
    "                 readout,\n",
    "                 conv_activation=F.relu,\n",
    "                 mlp_activation=F.relu):\n",
    "        super(ReflacxClassifier, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        new_conv = lambda in_feats, out_feats: GridConv(device,\n",
    "                                                        in_feats,\n",
    "                                                        out_feats,\n",
    "                                                        self.grid_size,\n",
    "                                                        pass_messages,\n",
    "                                                        conv_activation)\n",
    "        self.conv1 = new_conv(input_dim, input_dim)\n",
    "        self.conv2 = new_conv(input_dim, input_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(readout_dim, 4096).to(device)\n",
    "        self.fc2 = nn.Linear(4096, 4096).to(device)\n",
    "        self.fc3 = nn.Linear(4096, 1024).to(device)\n",
    "        \n",
    "        self.fcf = nn.Linear(1024, n_classes).to(device)\n",
    "        \n",
    "        self.readout = readout\n",
    "        self.conv_activation = conv_activation\n",
    "        self.mlp_activation = mlp_activation\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, graph, conv_feat_nm, grid_indices):\n",
    "        with graph.local_scope():\n",
    "            h = self.conv1(graph, conv_feat_nm, grid_indices)\n",
    "            h = self.conv2(graph, conv_feat_nm, grid_indices)\n",
    "            ro = self.readout(gridify_by_indices(graph, grid_indices))\n",
    "        h = self.mlp_activation(self.fc1(ro))\n",
    "        h = self.mlp_activation(self.fc2(h))\n",
    "        h = self.mlp_activation(self.fc3(h))\n",
    "        \n",
    "        return self.fcf(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ReflacxClassifier(device,\n",
    "                        1027,\n",
    "                        16448,\n",
    "                        6,\n",
    "                        grid_size,\n",
    "                        f_message,\n",
    "                        ReflacxReadout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = clf(batch, 'h', gridify_indices(batch, grid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading from DGL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data.utils import split_dataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = [0.8, 0.1, 0.1] # train, val, test\n",
    "batch_size = 100\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.CSVDataset(dataset_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularize duration and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regularization.regularization_pipeline import RegularizationPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full trainning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataset, regppl, batch_size, device, f_loss):\n",
    "    running_loss = 0\n",
    "    loader = GraphDataLoader(dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             drop_last=False)\n",
    "    graph_count = 0\n",
    "    \n",
    "    for i, (b, l) in enumerate(loader):\n",
    "        b = b.to(device)\n",
    "        l = l.to(device)\n",
    "        with b.local_scope():\n",
    "            init_graph(b)\n",
    "            regppl(b)\n",
    "            graph_indices = gridify_indices(b, grid_size)\n",
    "            h = model(b, 'h', graph_indices)\n",
    "        loss = f_loss(h, l)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        print('   batch {} loss: {}'.format(i, loss.item()))\n",
    "        running_loss += loss.item()\n",
    "        graph_count += b.batch_num_nodes().shape[0]\n",
    "    \n",
    "    return running_loss / graph_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs,\n",
    "          model,\n",
    "          dataset,\n",
    "          data_split,\n",
    "          batch_size,\n",
    "          device,\n",
    "          f_loss,\n",
    "          reg_node_nms,\n",
    "          reg_edge_nms=None,\n",
    "          model_pth='.'):\n",
    "    regppl = RegularizationPipeline(dataset, device, reg_node_nms, reg_edge_nms)\n",
    "    train, val, test = split_dataset(dataset, data_split, shuffle=True)\n",
    "    best_loss = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH: {}'.format(epoch + 1))\n",
    "\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(model,\n",
    "                                   train,\n",
    "                                   regppl,\n",
    "                                   batch_size,\n",
    "                                   device,\n",
    "                                   f_loss)\n",
    "        \n",
    "        print('Average TRAINNING loss: {}'.format(avg_loss))\n",
    "\n",
    "        eval_loss = 0\n",
    "        graph_count = 0\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loader = GraphDataLoader(val,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=False)\n",
    "            for b, l in loader:\n",
    "                b = b.to(device)\n",
    "                l = l.to(device)\n",
    "                with b.local_scope():\n",
    "                    init_graph(b)\n",
    "                    regppl(b)\n",
    "                    h = model(b, 'h', gridify_indices(b, grid_size))\n",
    "                eval_loss += f_loss(h, l).item()\n",
    "                graph_count += b.batch_num_nodes().shape[0]\n",
    "\n",
    "        avg_loss = eval_loss / graph_count\n",
    "        print('Average EVAL loss: {}\\n\\n'.format(avg_loss))\n",
    "\n",
    "        if best_loss is None or avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            pth = path.sep.join([model_pth,\n",
    "                                 'reflacx_densnet225_iou_{}.pt'.format(epoch)])\n",
    "            torch.save(model.state_dict(), pth)\n",
    "\n",
    "    test_loss = 0\n",
    "    graph_count = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loader = GraphDataLoader(test,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 drop_last=False)\n",
    "        for b, l in loader:\n",
    "            b = b.to(device)\n",
    "            l = l.to(device)\n",
    "            with b.local_scope():\n",
    "                init_graph(b)\n",
    "                regppl(b)\n",
    "                h = model(b, 'h', gridify_indices(b, grid_size))\n",
    "            test_loss += f_loss(h, l).item()\n",
    "            graph_count += b.batch_num_nodes().shape[0]\n",
    "\n",
    "    avg_loss = test_loss / graph_count\n",
    "    print('Average TEST loss after {} epochs: {}'.format(epochs, avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(epochs,\n",
    "            clf,\n",
    "            dataset,\n",
    "            data_split,\n",
    "            batch_size, device,\n",
    "            F.mse_loss,\n",
    "            ['duration', 'feats'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
